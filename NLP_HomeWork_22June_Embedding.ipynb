{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center;\"><span style=\"color: #000fff;\">Nagesh Buyre - 19MAI0024</span></h3>\n",
    "<h1 style=\"text-align: center;\">Natural Language Processing</h1>\n",
    "<h3 style=\"text-align: center;\">Activity - 2 (HomeWork 22june)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "As the Wikipedia will point out, word embedding is\n",
    "‘the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer object\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "          'Text of first document.',\n",
    "          'Text of the second document made longer.',\n",
    "          'Number three.',\n",
    "          'This is number four.',\n",
    "]\n",
    "\n",
    "# learn the vocabulary and store CountVectorizer sparse matrix in X\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# columns of X correspond to the result of this method\n",
    "vectorizer.get_feature_names() == (\n",
    "    ['document', 'first', 'four', 'is', 'longer',\n",
    "     'made', 'number', 'of', 'second', 'text',\n",
    "     'the', 'this', 'three'])\n",
    "\n",
    "# retrieving the matrix in the numpy form\n",
    "X.toarray()\n",
    "\n",
    "\n",
    "# transforming a new document according to learn vocabulary\n",
    "vectorizer.transform(['A new document.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81940995, 0.        , 0.57320793],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.47330339, 0.88089948, 0.        ],\n",
       "       [0.33653362, 0.        , 0.94167145]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tf-idf \n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "\n",
    "\n",
    "# X can be obtained as X.toarray() from the previous snippet\n",
    "X = [[3, 0, 1],\n",
    "     [5, 0, 0],\n",
    "     [3, 0, 0],\n",
    "     [1, 0, 0],\n",
    "     [3, 2, 0],\n",
    "     [3, 0, 4]]\n",
    "\n",
    "\n",
    "# learn the vocabulary and store tf-idf sparse matrix in tfidf\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "# retrieving matrix in numpy form as we did it before\n",
    "tfidf.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "\n",
    "from gensim.models import word2vec\n",
    "corpus = [\n",
    "          'Text of the first document.',\n",
    "          'Text of the second document made longer.',\n",
    "          'Number three.',\n",
    "          'This is number four.',\n",
    "]\n",
    "# we need to pass splitted sentences to the model\n",
    "tokenized_sentences = [sentence.split() for sentence in corpus]\n",
    "model = word2vec.Word2Vec(tokenized_sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014918448"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('Text', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Text', 'of', 'the', 'first', 'document.'],\n",
       " ['Text', 'of', 'the', 'second', 'document', 'made', 'longer.'],\n",
       " ['Number', 'three.'],\n",
       " ['This', 'is', 'number', 'four.']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TO WHOMSOEVER IT MAY CONCERN  I am pleased to recommend MrXX for an MS in Computer Science at your esteemed university. I have known him since his second year. He was my student in the 3rd semester (2nd year), where I taught him the course of Database Management Systems.  I first got to know X in the course of Database Management Systems, CSE-2004. In the first week of the course, I was surprised to know that X, an Electronics and Instrumentation student, had taken up a computer science core course. Initially I was doubtful about a non-CS student’s approach and grasp of the subject, but he adapted to it as naturally as a fish to water. By the time the course came to an end, he had proved his mettle.  I observed that X had a keen interest and was fully involved in the course when I saw his performances during the Lab sessions, where he would be able to grasp new concepts such as query formation and joins. He has been highly active in the technical scene of our college too with him organizing many events. As a part of the course, students are required to develop a project, with a fully functional Database System consisting of the concepts learnt throughout the semester. Despite X not being from a computer science background, his project did not languish. He went above and beyond to make a professional database design, which included an ‘Auto-Increment’ feature using a PL/SQL sequence written by him, bulk insertion into the table and other features. I was pleased to know that he applied the concepts in his internship extensively to build a professional tool for Intellect Design Arena. He designed this tool to make the process of configuring a Logical Data Model easier and much faster. It consisted of a User Interface (UI) that can replicate back-end tasks such as inserting data in a database at the click of a button. His task was cut out for him as the tool was being built for J.P. Morgan Chase as a client and hence there was no room for error. I am proud to say that the tool, which he built over a course of two months, was pushed to production at the end of his internship. X makes a strong candidate for your Master's program majoring in Computer Science. His proposed candidature has my endorsement without any reservations whatsoever.  \""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Reads file \n",
    "sample = open(\"E:/3rd_sem/NLP/lab/LoR Sample 1.txt\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") \n",
    "  \n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['to',\n",
       "  'whomsoever',\n",
       "  'it',\n",
       "  'may',\n",
       "  'concern',\n",
       "  'i',\n",
       "  'am',\n",
       "  'pleased',\n",
       "  'to',\n",
       "  'recommend',\n",
       "  'mrxx',\n",
       "  'for',\n",
       "  'an',\n",
       "  'ms',\n",
       "  'in',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'at',\n",
       "  'your',\n",
       "  'esteemed',\n",
       "  'university',\n",
       "  '.'],\n",
       " ['i', 'have', 'known', 'him', 'since', 'his', 'second', 'year', '.'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'my',\n",
       "  'student',\n",
       "  'in',\n",
       "  'the',\n",
       "  '3rd',\n",
       "  'semester',\n",
       "  '(',\n",
       "  '2nd',\n",
       "  'year',\n",
       "  ')',\n",
       "  ',',\n",
       "  'where',\n",
       "  'i',\n",
       "  'taught',\n",
       "  'him',\n",
       "  'the',\n",
       "  'course',\n",
       "  'of',\n",
       "  'database',\n",
       "  'management',\n",
       "  'systems',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'first',\n",
       "  'got',\n",
       "  'to',\n",
       "  'know',\n",
       "  'x',\n",
       "  'in',\n",
       "  'the',\n",
       "  'course',\n",
       "  'of',\n",
       "  'database',\n",
       "  'management',\n",
       "  'systems',\n",
       "  ',',\n",
       "  'cse-2004',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'week',\n",
       "  'of',\n",
       "  'the',\n",
       "  'course',\n",
       "  ',',\n",
       "  'i',\n",
       "  'was',\n",
       "  'surprised',\n",
       "  'to',\n",
       "  'know',\n",
       "  'that',\n",
       "  'x',\n",
       "  ',',\n",
       "  'an',\n",
       "  'electronics',\n",
       "  'and',\n",
       "  'instrumentation',\n",
       "  'student',\n",
       "  ',',\n",
       "  'had',\n",
       "  'taken',\n",
       "  'up',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'core',\n",
       "  'course',\n",
       "  '.'],\n",
       " ['initially',\n",
       "  'i',\n",
       "  'was',\n",
       "  'doubtful',\n",
       "  'about',\n",
       "  'a',\n",
       "  'non-cs',\n",
       "  'student',\n",
       "  '’',\n",
       "  's',\n",
       "  'approach',\n",
       "  'and',\n",
       "  'grasp',\n",
       "  'of',\n",
       "  'the',\n",
       "  'subject',\n",
       "  ',',\n",
       "  'but',\n",
       "  'he',\n",
       "  'adapted',\n",
       "  'to',\n",
       "  'it',\n",
       "  'as',\n",
       "  'naturally',\n",
       "  'as',\n",
       "  'a',\n",
       "  'fish',\n",
       "  'to',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['by',\n",
       "  'the',\n",
       "  'time',\n",
       "  'the',\n",
       "  'course',\n",
       "  'came',\n",
       "  'to',\n",
       "  'an',\n",
       "  'end',\n",
       "  ',',\n",
       "  'he',\n",
       "  'had',\n",
       "  'proved',\n",
       "  'his',\n",
       "  'mettle',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'observed',\n",
       "  'that',\n",
       "  'x',\n",
       "  'had',\n",
       "  'a',\n",
       "  'keen',\n",
       "  'interest',\n",
       "  'and',\n",
       "  'was',\n",
       "  'fully',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'course',\n",
       "  'when',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'his',\n",
       "  'performances',\n",
       "  'during',\n",
       "  'the',\n",
       "  'lab',\n",
       "  'sessions',\n",
       "  ',',\n",
       "  'where',\n",
       "  'he',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'grasp',\n",
       "  'new',\n",
       "  'concepts',\n",
       "  'such',\n",
       "  'as',\n",
       "  'query',\n",
       "  'formation',\n",
       "  'and',\n",
       "  'joins',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'has',\n",
       "  'been',\n",
       "  'highly',\n",
       "  'active',\n",
       "  'in',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'scene',\n",
       "  'of',\n",
       "  'our',\n",
       "  'college',\n",
       "  'too',\n",
       "  'with',\n",
       "  'him',\n",
       "  'organizing',\n",
       "  'many',\n",
       "  'events',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'a',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'course',\n",
       "  ',',\n",
       "  'students',\n",
       "  'are',\n",
       "  'required',\n",
       "  'to',\n",
       "  'develop',\n",
       "  'a',\n",
       "  'project',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'fully',\n",
       "  'functional',\n",
       "  'database',\n",
       "  'system',\n",
       "  'consisting',\n",
       "  'of',\n",
       "  'the',\n",
       "  'concepts',\n",
       "  'learnt',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'semester',\n",
       "  '.'],\n",
       " ['despite',\n",
       "  'x',\n",
       "  'not',\n",
       "  'being',\n",
       "  'from',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'background',\n",
       "  ',',\n",
       "  'his',\n",
       "  'project',\n",
       "  'did',\n",
       "  'not',\n",
       "  'languish',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'went',\n",
       "  'above',\n",
       "  'and',\n",
       "  'beyond',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'professional',\n",
       "  'database',\n",
       "  'design',\n",
       "  ',',\n",
       "  'which',\n",
       "  'included',\n",
       "  'an',\n",
       "  '‘',\n",
       "  'auto-increment',\n",
       "  '’',\n",
       "  'feature',\n",
       "  'using',\n",
       "  'a',\n",
       "  'pl/sql',\n",
       "  'sequence',\n",
       "  'written',\n",
       "  'by',\n",
       "  'him',\n",
       "  ',',\n",
       "  'bulk',\n",
       "  'insertion',\n",
       "  'into',\n",
       "  'the',\n",
       "  'table',\n",
       "  'and',\n",
       "  'other',\n",
       "  'features',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'pleased',\n",
       "  'to',\n",
       "  'know',\n",
       "  'that',\n",
       "  'he',\n",
       "  'applied',\n",
       "  'the',\n",
       "  'concepts',\n",
       "  'in',\n",
       "  'his',\n",
       "  'internship',\n",
       "  'extensively',\n",
       "  'to',\n",
       "  'build',\n",
       "  'a',\n",
       "  'professional',\n",
       "  'tool',\n",
       "  'for',\n",
       "  'intellect',\n",
       "  'design',\n",
       "  'arena',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'designed',\n",
       "  'this',\n",
       "  'tool',\n",
       "  'to',\n",
       "  'make',\n",
       "  'the',\n",
       "  'process',\n",
       "  'of',\n",
       "  'configuring',\n",
       "  'a',\n",
       "  'logical',\n",
       "  'data',\n",
       "  'model',\n",
       "  'easier',\n",
       "  'and',\n",
       "  'much',\n",
       "  'faster',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'consisted',\n",
       "  'of',\n",
       "  'a',\n",
       "  'user',\n",
       "  'interface',\n",
       "  '(',\n",
       "  'ui',\n",
       "  ')',\n",
       "  'that',\n",
       "  'can',\n",
       "  'replicate',\n",
       "  'back-end',\n",
       "  'tasks',\n",
       "  'such',\n",
       "  'as',\n",
       "  'inserting',\n",
       "  'data',\n",
       "  'in',\n",
       "  'a',\n",
       "  'database',\n",
       "  'at',\n",
       "  'the',\n",
       "  'click',\n",
       "  'of',\n",
       "  'a',\n",
       "  'button',\n",
       "  '.'],\n",
       " ['his',\n",
       "  'task',\n",
       "  'was',\n",
       "  'cut',\n",
       "  'out',\n",
       "  'for',\n",
       "  'him',\n",
       "  'as',\n",
       "  'the',\n",
       "  'tool',\n",
       "  'was',\n",
       "  'being',\n",
       "  'built',\n",
       "  'for',\n",
       "  'j.p.',\n",
       "  'morgan',\n",
       "  'chase',\n",
       "  'as',\n",
       "  'a',\n",
       "  'client',\n",
       "  'and',\n",
       "  'hence',\n",
       "  'there',\n",
       "  'was',\n",
       "  'no',\n",
       "  'room',\n",
       "  'for',\n",
       "  'error',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'proud',\n",
       "  'to',\n",
       "  'say',\n",
       "  'that',\n",
       "  'the',\n",
       "  'tool',\n",
       "  ',',\n",
       "  'which',\n",
       "  'he',\n",
       "  'built',\n",
       "  'over',\n",
       "  'a',\n",
       "  'course',\n",
       "  'of',\n",
       "  'two',\n",
       "  'months',\n",
       "  ',',\n",
       "  'was',\n",
       "  'pushed',\n",
       "  'to',\n",
       "  'production',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'his',\n",
       "  'internship',\n",
       "  '.'],\n",
       " ['x',\n",
       "  'makes',\n",
       "  'a',\n",
       "  'strong',\n",
       "  'candidate',\n",
       "  'for',\n",
       "  'your',\n",
       "  'master',\n",
       "  \"'s\",\n",
       "  'program',\n",
       "  'majoring',\n",
       "  'in',\n",
       "  'computer',\n",
       "  'science',\n",
       "  '.'],\n",
       " ['his',\n",
       "  'proposed',\n",
       "  'candidature',\n",
       "  'has',\n",
       "  'my',\n",
       "  'endorsement',\n",
       "  'without',\n",
       "  'any',\n",
       "  'reservations',\n",
       "  'whatsoever',\n",
       "  '.']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "data = [] \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09077449"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              size = 100, window = 5) \n",
    "  \n",
    "model1.similarity('course', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11197839"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Skip Gram model \n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1) \n",
    "  \n",
    "model2.similarity('course', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
